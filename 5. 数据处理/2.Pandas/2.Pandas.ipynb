{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.Pandas简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Pandas vs NumPy vs SciPy选型决策流程图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.Pandas核心定位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Pandas 环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 标准的 Python 发行版不会与 Pandas 模块捆绑在一起。<br>\n",
    "一个轻量级的替代方法是使用流行的 Python 包安装程序 pip 来安装 Pandas。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.使用手册"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/docs/user_guide/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas专注于数据分析和表格操作，适合处理结构化数据（如 CSV、Excel 等）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 特点             | pandas                          | scipy                                   | numpy                                   |\n",
    "|------------------|---------------------------------|------------------------------------------|------------------------------------------|\n",
    "| 主要用途         | 处理表格数据，适合做数据分析 | 高级科学计算（数值优化、统计等）     | 做数学运算，尤其是数组相关         |\n",
    "| 数据结构         | 基于 numpy 的“表格”型数据      | 基于 NumPy 的多种科学计算模块       | “数组”型，类似数字列表             |\n",
    "| 处理数据类型     | 可以处理不同类型的数据（数字、文字、日期等） | 专注于科学计算（矩阵运算、统计）     | 主要处理数字数据                     |\n",
    "| 索引功能         | 支持标签                        | 不支持标签                               | 不支持标签                             |\n",
    "| 缺失值处理       | 支持                           | 不支持                                   | 不支持                                 |\n",
    "| 功能           | 数据清洗、统计、分组、合并等     | 优化、插值、线性代数、信号处理等         | 加减乘除、数组运算                       |\n",
    "| 速度           | 功能更多，处理的事物复杂         | 与 NumPy 类似                           | 更快，专注于高效的数值计算             |\n",
    "| 适用场景         | 数据分析、数据清洗、表格数据处理 | 复杂科学问题的建模和解决               | 数学运算、大规模的数值计算             |\n",
    "| 时间日期处理       | 支持处理时间数据（时间序列等）   | 不支持时间序列                           | 不支持处理时间和日期数据                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02.数据导入导出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.数据导入操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.导入 CSV 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 导入 CSV 文件\u001b[39;00m\n",
      "\u001b[32m      4\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mfile_path.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 导入 CSV 文件\n",
    "df = pd.read_csv('file_path.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.导入 Excel 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 导入 Excel 文件，并指定读取的工作表\u001b[39;00m\n",
      "\u001b[32m      4\u001b[39m df = pd.read_excel(\u001b[33m'\u001b[39m\u001b[33mfile_path.xlsx\u001b[39m\u001b[33m'\u001b[39m, sheet_name=\u001b[33m'\u001b[39m\u001b[33mSheet1\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 导入 Excel 文件，并指定读取的工作表\n",
    "df = pd.read_excel('file_path.xlsx', sheet_name='Sheet1')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.导入 JSON 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 导入 JSON 文件\n",
    "df = pd.read_json('file_path.json')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.导入 SQL 数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# 连接到 SQLite 数据库\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# 从 SQL 数据库中读取数据\n",
    "df = pd.read_sql('SELECT * FROM table_name', conn)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5.导入 HDF5 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 导入 HDF5 文件\n",
    "df = pd.read_hdf('file_path.h5')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.导入 HTML 表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 从 HTML 文件中导入表格数据\n",
    "df_list = pd.read_html('file_path.html')\n",
    "\n",
    "# 如果有多个表格，选择其中一个\n",
    "df = df_list[0]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.7.导入Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "\n",
    "# 使用 gspread 库连接到 Google Sheets\n",
    "gc = gspread.service_account(filename='path/to/your/service_account.json')\n",
    "\n",
    "# 打开 Google Sheet 文件并获取工作表\n",
    "worksheet = gc.open('sheet_name').sheet1\n",
    "\n",
    "# 将 Google Sheets 数据转换为 DataFrame\n",
    "data = worksheet.get_all_records()\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.数据导出操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.导出到 CSV 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 将 DataFrame 导出到 CSV 文件，index=False 不包含行索引\u001b[39;00m\n",
      "\u001b[32m      4\u001b[39m df.to_csv(\u001b[33m'\u001b[39m\u001b[33mfile_path.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 将 DataFrame 导出到 CSV 文件，index=False 不包含行索引\n",
    "df.to_csv('file_path.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.导出到 Excel 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 将 DataFrame 导出到 Excel 文件，并指定工作表名称，index=False 不包含行索引\n",
    "df.to_excel('file_path.xlsx', sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.导出到 JSON 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 将 DataFrame 导出到 JSON 文件\n",
    "df.to_json('file_path.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4. 导出到 SQL 数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# 连接到 SQLite 数据库\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# 将 DataFrame 导出到 SQL 数据库\n",
    "df.to_sql('table_name', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.导出到 HDF5 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 将 DataFrame 导出到 HDF5 文件\n",
    "df.to_hdf('file_path.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.6.导出到 HTML 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 将 DataFrame 导出到 HTML 文件\n",
    "df.to_html('file_path.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.7.导出到 Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "\n",
    "# 使用 gspread 库连接到 Google Sheets\n",
    "gc = gspread.service_account(filename='path/to/your/service_account.json')\n",
    "\n",
    "# 打开 Google Sheet 文件并获取工作表\n",
    "worksheet = gc.open('sheet_name').sheet1\n",
    "\n",
    "# 将 DataFrame 更新到 Google Sheets\n",
    "worksheet.update([df.columns.values.tolist()] + df.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.数据筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.创建、重命名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作类型 | Series | DataFrame | 解释 |\n",
    "|----------|--------|-----------|---------|\n",
    "| 创建 | `s = pd.Series(data, index=[])` | `df = pd.DataFrame(data)` | Series: 一维数据（默认索引0开始）<br>DataFrame: 二维数据（默认行列索引是0） |\n",
    "| 重命名 | `s.rename(index={'old': 'new'})` | `df.rename(columns={'old_name': 'new_name'})` | Series 只能重命名索引<br>DataFrame 可以重命名行列名 |\n",
    "| 设置索引 | 不支持设置索引（索引在创建时定义） | `df.set_index('column_name')` | Series: 在创建时已定义，后续无法更改<br>DataFrame: 支持后续修改 |\n",
    "| 重置索引 | 不支持 | `df.reset_index()` | Series: 不支持<br>DataFrame: 可以重置为默认的整数索引 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.创建Series 和 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 第一部分：创建Series =====================\n",
    "import pandas as pd\n",
    "\n",
    "# 创建Series示例\n",
    "data = [10, 20, 30, 40]  # 数据列表\n",
    "s = pd.Series(data, index=['a', 'b', 'c', 'd'])  # 创建带自定义索引的Series\n",
    "\n",
    "print(\"创建的 Series:\")\n",
    "print(s)\n",
    "print('=========================Series创建=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.重命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 第三部分：重命名操作 =====================\n",
    "import pandas as pd\n",
    "\n",
    "# 假设已有Series s和DataFrame df\n",
    "\n",
    "# Series重命名索引\n",
    "s_renamed = s.rename(index={'a': 'A'})  # 将索引'a'重命名为'A'\n",
    "\n",
    "print(\"\\n重命名 Series 中索引 'a' 为 'A':\")\n",
    "print(s_renamed)\n",
    "\n",
    "# DataFrame重命名列\n",
    "df_renamed = df.rename(columns={'Name': 'Full Name'})  # 将'Name'列重命名为'Full Name'\n",
    "\n",
    "print(\"\\n重命名 DataFrame 中 'Name' 列为 'Full Name':\")\n",
    "print(df_renamed)\n",
    "print('=========================重命名=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.重置索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 第四部分：设置与重置索引 =====================\n",
    "import pandas as pd\n",
    "\n",
    "# 假设已有DataFrame df\n",
    "\n",
    "# 设置索引\n",
    "df_set_index = df.set_index('Name')  # 将'Name'列设置为索引\n",
    "print(\"\\n设置 DataFrame 中 'Name' 列为索引:\")\n",
    "print(df_set_index)\n",
    "\n",
    "# 重置索引\n",
    "df_reset_index = df_set_index.reset_index()  # 将索引重置为默认整数索引\n",
    "print(\"\\n重置 DataFrame 索引:\")\n",
    "print(df_reset_index)\n",
    "print('=========================设置与重置索引=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.增删改查相关操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作类型 | Series | DataFrame | 解释 |\n",
    "|-----------|---------|-----------|---------|\n",
    "| 增加<br>添加数据 | `s.loc[new_index] = new_value`<br>`s[index] = new_value` | 行：`df.loc[new_index] = new_value`<br>列：`df['new_column'] = value` | Series：通过索引覆盖添加元素<br>DataFrame：通过行列覆盖添加元素 |\n",
    "| 填充缺失值 | `s.fillna(value)` | `df.fillna(value)` | Series：通过指定索引寻找 NaN 覆盖添加<br>DataFrame：通过指定行列寻找 NaN 覆盖添加 |\n",
    "| 删除<br>删除数据 | `s.drop(index)` | 行：`df.drop(index, axis=0)`<br>列：`df.drop('column_name', axis=1)` | Series：只能删除元素<br>DataFrame：可以删除行列 |\n",
    "| 删除重复值 | `s.drop_duplicates()` | `df.drop_duplicates()` | 自动保留第一个，删除其余重复元素。 |\n",
    "| 删除缺失值 | `s.dropna()` | `df.dropna()` | 删除包含缺失值的元素或一整行 |\n",
    "| 修改<br>修改数据 | `s.loc[new_index] = new_value`<br>`s[index] = new_value` | 行：`df.loc[new_index] = new_value`<br>列：`df['new_column'] = value` | 与添加数据语法一致，本质上是覆盖 |\n",
    "| 合并 | `pd.concat([s1, s2], axis=0)` | 行：`pd.concat([df1, df2], axis=0)`<br>列：`pd.concat([df1, df2], axis=1)`<br>`pd.merge(df1, df2, on='key', how='inner')`<br>`df1.join(df2)` | axis=0 指行<br>axis=1 指列 |\n",
    "| 查看<br>查看 | 查看前几项 | `s.head(n)` | `df.head(n)` | 查看前n行，默认前 5 行 |\n",
    "| 查看后几项 | `s.tail(n)` | `df.tail(n)` | 查看末尾n行，默认末尾 5 行 |\n",
    "| 查看数据 | `s.values` | `df.values` | 返回值信息 |\n",
    "| 查看索引 | `s.index` | `df.index` | 获取行索引信息 |\n",
    "| 选择列 | - | `df[['col1', 'col2'...]]` | 通过多个列名选择多列数据 |\n",
    "| 选择行 | `s.iloc[start:stop:step]`<br>`s.iloc[index]` | 行：`df.iloc[start:stop:step]`<br>列：`df.iloc[:,index...]` | 使用整数索引选择单行数据 |\n",
    "| 选择索引交叉位置的值 | `s.iloc[index]` | 行：`df.iloc[row_index]`<br>列：`df.iloc[:,column_index]` | 基于位置选择数据 |\n",
    "| 选择标签交叉位置的值 | `s.loc[index]` | 行列：`df.loc[row_label, column_label]`<br>行：`df.loc[row_label]`<br>列：`df['col_name']` | 基于标签选择数据 |\n",
    "| 按多条件选择数据 | `s[s > value]` | 多条件：`df[(df['column1'] > value1) & (df['column2'] < value2)]`<br>嵌套：`df.loc[条件, ['column1', 'column2']]` | 根据&、|、==、!= 的条件筛选数据 |\n",
    "| 按行列切片选择数据 | `s[start:end]` | 行：`df[行(start:stop:step), 列(start:stop:step)]` | 使用切片（:）选择数据，返回指定范围的行和列。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.导入库和创建基础数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 创建Series示例\n",
    "data_series = [10, 20, 30, 40]\n",
    "s = pd.Series(data_series, index=['a', 'b', 'c', 'd'])\n",
    "print(\"创建的 Series:\")\n",
    "print(s)\n",
    "\n",
    "# 创建DataFrame示例\n",
    "data_dict = {'Name': ['Alice', 'Bob', 'Charlie'], \n",
    "             'Age': [25, 30, 35], \n",
    "             'City': ['New York', 'Los Angeles', 'Chicago']}\n",
    "df = pd.DataFrame(data_dict)\n",
    "print(\"\\n创建的 DataFrame:\")\n",
    "print(df)\n",
    "print('===========================创建示例=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.数据添加操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加数据到Series\n",
    "s.loc['e'] = 50  # 通过新索引添加元素\n",
    "\n",
    "# 添加数据到DataFrame\n",
    "df['Country'] = ['USA', 'USA', 'USA']  # 添加新列\n",
    "df.loc[2, 'City'] = 'San Francisco'  # 修改特定单元格\n",
    "\n",
    "print(\"\\n添加数据:\")\n",
    "print(\"Series 添加新数据:\")\n",
    "print(s)\n",
    "print(\"DataFrame 添加新列:\")\n",
    "print(df)\n",
    "print('===========================添加示例=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series缺失值处理\n",
    "s_with_na = s.copy()\n",
    "s_with_na['b'] = np.nan  # 添加缺失值\n",
    "s_filled = s_with_na.fillna(99)  # 填充缺失值\n",
    "\n",
    "# DataFrame缺失值处理\n",
    "df_with_na = df.copy()\n",
    "df_with_na.loc[1, 'Age'] = pd.NA\n",
    "df_with_na.loc[1, 'City'] = np.nan\n",
    "df_filled = df_with_na.fillna({'Age': 40, 'City': 'Unknown'})  # 按列填充不同值\n",
    "\n",
    "print(\"\\n填充缺失值:\")\n",
    "print(\"Series 填充缺失值:\")\n",
    "print(s_filled)\n",
    "print(\"DataFrame 填充缺失值:\")\n",
    "print(df_filled)\n",
    "print('===========================填充示例=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.数据删除操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按索引删除Series元素\n",
    "s_dropped = s.drop('b')\n",
    "print(\"\\n删除 Series 中索引 'b' 的元素:\")\n",
    "print(s_dropped)\n",
    "print('=========================按索引删除=========================')\n",
    "\n",
    "# DataFrame删除操作\n",
    "df_dropped_row = df.drop(1, axis=0)  # 删除行\n",
    "df_dropped_col = df.drop('City', axis=1)  # 删除列\n",
    "\n",
    "print(\"\\n删除 DataFrame 中索引为 1 的行:\")\n",
    "print(df_dropped_row)\n",
    "print(\"\\n删除 DataFrame 中 'City' 列:\")\n",
    "print(df_dropped_col)\n",
    "print('=========================按行列删除=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5.重复数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建重复数据示例\n",
    "s_duplicate = pd.Series([10, 20, 20, 40, 40, 40])\n",
    "df_duplicate = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Bob', 'Charlie', 'Charlie', 'Charlie'],\n",
    "    'Age': [25, 30, 30, 35, 35, 35]\n",
    "})\n",
    "\n",
    "# 删除重复数据\n",
    "s_no_duplicates = s_duplicate.drop_duplicates()\n",
    "df_no_duplicates = df_duplicate.drop_duplicates()\n",
    "\n",
    "print(\"\\n删除重复数据:\")\n",
    "print(\"Series 删除重复值:\")\n",
    "print(s_no_duplicates)\n",
    "print(\"DataFrame 删除重复行:\")\n",
    "print(df_no_duplicates)\n",
    "print('===========================删除重复示例=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.6.缺失值删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建含缺失值的数据\n",
    "s_with_na_2 = s.copy()\n",
    "s_with_na_2['c'] = np.nan\n",
    "df_with_na_2 = df.copy()\n",
    "df_with_na_2.loc[0, 'Age'] = np.nan\n",
    "\n",
    "# 删除缺失值\n",
    "s_without_na = s_with_na_2.dropna()\n",
    "df_without_na = df_with_na_2.dropna()\n",
    "\n",
    "print(\"\\n删除缺失值:\")\n",
    "print(\"Series 删除缺失值:\")\n",
    "print(s_without_na)\n",
    "print(\"DataFrame 删除缺失值:\")\n",
    "print(df_without_na)\n",
    "print('===========================删除缺失示例=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.7.数据修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改Series数据\n",
    "s['a'] = 100\n",
    "\n",
    "# 修改DataFrame数据\n",
    "df['Age'] = [26, 31, 36]\n",
    "\n",
    "print(\"\\n修改数据:\")\n",
    "print(\"Series 修改数据:\")\n",
    "print(s)\n",
    "print(\"DataFrame 修改数据:\")\n",
    "print(df)\n",
    "print('===========================修改示例=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.8.数据合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建要合并的数据\n",
    "s2 = pd.Series([50, 60, 70], index=['e', 'f', 'g'])\n",
    "df2 = pd.DataFrame({\n",
    "    'Name': ['David', 'Eva'],\n",
    "    'Age': [40, 45],\n",
    "    'City': ['Seattle', 'Austin']\n",
    "})\n",
    "\n",
    "# 合并操作\n",
    "s_merged = pd.concat([s, s2], axis=0)  # Series合并\n",
    "df_merged = pd.concat([df, df2], axis=0)  # DataFrame行合并\n",
    "df_merged_columns = pd.concat([df, df2], axis=1)  # DataFrame列合并\n",
    "\n",
    "print(\"\\n合并数据:\")\n",
    "print(\"Series 合并:\")\n",
    "print(s_merged)\n",
    "print(\"DataFrame 按行合并:\")\n",
    "print(df_merged)\n",
    "print(\"DataFrame 按列合并:\")\n",
    "print(df_merged_columns)\n",
    "print('===========================合并示例=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.9.数据查看操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看前后几项\n",
    "print(\"\\n查看前几项:\")\n",
    "print(\"Series 前 3 项:\")\n",
    "print(s.head(3))\n",
    "print(\"DataFrame 前 2 行:\")\n",
    "print(df.head(2))\n",
    "\n",
    "print(\"\\n查看后几项:\")\n",
    "print(\"Series 后 2 项:\")\n",
    "print(s.tail(2))\n",
    "print(\"DataFrame 后 1 行:\")\n",
    "print(df.tail(1))\n",
    "print('===========================查看前后项示例=========================')\n",
    "\n",
    "# 查看数据值\n",
    "print(\"\\n查看数据:\")\n",
    "print(\"Series 的值:\")\n",
    "print(s.values)\n",
    "print(\"DataFrame 的值:\")\n",
    "print(df.values)\n",
    "print('===========================查看数据示例=========================')\n",
    "\n",
    "# 查看索引\n",
    "print(\"\\n查看索引:\")\n",
    "print(\"Series 的索引:\")\n",
    "print(s.index)\n",
    "print(\"DataFrame 的索引:\")\n",
    "print(df.index)\n",
    "print('===========================查看索引示例=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.10.数据选择操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按位置选择\n",
    "print(\"\\n按位置选择数据:\")\n",
    "print(\"Series 按位置选择（第 2 个元素）:\")\n",
    "print(s.iloc[1])\n",
    "print(\"DataFrame 按位置选择（第 2 行）:\")\n",
    "print(df.iloc[1])\n",
    "print('==========================查看位置示例=========================')\n",
    "\n",
    "# 按标签选择\n",
    "print(\"\\n按标签选择数据:\")\n",
    "print(\"Series 按标签选择（索引 'a' 的元素）:\")\n",
    "print(s.loc['a'])\n",
    "print(\"DataFrame 按标签选择（行标签为 'Bob'）:\")\n",
    "print(df.loc[1])\n",
    "print(\"DataFrame 按标签选择（列 'City' 的数据）:\")\n",
    "print(df['City'])\n",
    "print('==========================查看标签示例=========================')\n",
    "\n",
    "# 按条件选择\n",
    "print(\"\\n按条件选择数据:\")\n",
    "print(\"Series 按条件选择（大于 20 的元素）:\")\n",
    "print(s[s > 20])\n",
    "print(\"DataFrame 按条件选择（Age 大于 30 的行）:\")\n",
    "print(df[df['Age'] > 30])\n",
    "print('==========================查看条件示例=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.行列交换与排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作类型       | 语法                                      | 通俗解释                                                                 | 应用场景                                                                 |\n",
    "|----------------|------------------------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| 行列转置       | `df.T`                                   | 将行列互换，返回 DataFrame 的转置。                                      | 适用于数据的行列交换                                                    |\n",
    "| 按行排序       | `df.sort_values(by='column_name')`      | 根据列值对 DataFrame 按行排序，by 指定要排序的列名，默认升序排序，`ascending=False` 为降序。 | 用于排序数据，例如按成绩、收入等对数据进行排序。                         |\n",
    "| 按列排序       | `df.sort_index(axis=1)`                 | 根据列索引对 DataFrame 按列排序，`axis=1` 表示按列排序。                 | 用于按列名称对数据进行排序。                                             |\n",
    "| 按多列排序     | `df.sort_values(by=['col1', 'col2'])`   | 根据多列数据进行排序                                                     | 按多个指标（如销售额、日期）对数据进行排序。                             |\n",
    "| 按多行排序     | `df.sort_values(by=['row1', 'row2'], ascending=[True, False])` | 根据多行数据进行排序                                                     | 按多个个体对数据进行排序。                                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我将把这段代码分成几个逻辑部分，并为每个部分添加详细注释："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.创建示例DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建示例DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Score': [88, 92, 85, 79]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"原始DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.行列转置操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行列转置 - 使用.T属性将行和列互换\n",
    "df_transposed = df.T  # 或者使用 df.transpose()\n",
    "\n",
    "print(\"行列转置结果:\")\n",
    "print(df_transposed)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.按单列排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按单列排序 - 根据'Score'列进行降序排序\n",
    "df_sorted_by_score = df.sort_values(by='Score', ascending=False)\n",
    "\n",
    "print(\"按'Score'列降序排序结果:\")\n",
    "print(df_sorted_by_score)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.按列名排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按列名排序 - 根据列索引(列名)进行排序\n",
    "df_sorted_by_columns = df.sort_index(axis=1)  # axis=1表示按列排序\n",
    "\n",
    "print(\"按列索引排序结果:\")\n",
    "print(df_sorted_by_columns)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.按多列排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 按多列排序 - 先按'Age'升序，再按'Score'降序\n",
    "df_sorted_by_multiple_columns = df.sort_values(\n",
    "    by=['Age', 'Score'], \n",
    "    ascending=[True, False]  # 第一个True对应Age升序，第二个False对应Score降序\n",
    ")\n",
    "\n",
    "print(\"按'Age'升序和'Score'降序排序结果:\")\n",
    "print(df_sorted_by_multiple_columns)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6.模拟按多行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 模拟按多行排序 - 实际上DataFrame没有直接按行排序的方法\u001b[39;00m\n",
      "\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 这里通过转置后按列排序，再转置回来实现类似效果\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_sorted_by_rows = \u001b[43mdf\u001b[49m.T.sort_values(\n",
      "\u001b[32m      4\u001b[39m     by=[\u001b[33m'\u001b[39m\u001b[33mAge\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mScore\u001b[39m\u001b[33m'\u001b[39m],  \u001b[38;5;66;03m# 选择要排序的行标签\u001b[39;00m\n",
      "\u001b[32m      5\u001b[39m     ascending=[\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]  \u001b[38;5;66;03m# 排序顺序\u001b[39;00m\n",
      "\u001b[32m      6\u001b[39m ).T  \u001b[38;5;66;03m# 最后再转置回来\u001b[39;00m\n",
      "\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m模拟按\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAge\u001b[39m\u001b[33m'\u001b[39m\u001b[33m和\u001b[39m\u001b[33m'\u001b[39m\u001b[33mScore\u001b[39m\u001b[33m'\u001b[39m\u001b[33m多行排序结果:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_sorted_by_rows)\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 模拟按多行排序 - 实际上DataFrame没有直接按行排序的方法\n",
    "# 这里通过转置后按列排序，再转置回来实现类似效果\n",
    "df_sorted_by_rows = df.T.sort_values(\n",
    "    by=['Age', 'Score'],  # 选择要排序的行标签\n",
    "    ascending=[True, False]  # 排序顺序\n",
    ").T  # 最后再转置回来\n",
    "\n",
    "print(\"模拟按'Age'和'Score'多行排序结果:\")\n",
    "print(df_sorted_by_rows)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 方面       | Series                      | DataFrame                      | 应用场景                                                                 |\n",
    "|------------|-----------------------------|--------------------------------|--------------------------------------------------------------------------|\n",
    "| 数据结构   | 一维带标签的纵向列表        | 二维电子表格或数据库表         | Series 适用于存储单一属性的数据，如一列温度记录<br>DataFrame 适用于存储多属性的数据，如学生成绩表 |\n",
    "| 索引       | 只有行索引                  | 行索引和列索引                 | Series 仅有一个索引，便于单列操作<br>DataFrame 有行和列索引，支持更复杂的数据操作 |\n",
    "| 数据类型   | 支持多种数据类型            | 支持多种数据类型               | 数值、字符串等                                                          |\n",
    "| 内存使用   | 较低                        | 较高                           | Series 在处理单列数据时更节省内存<br>DataFrame 因为多列数据，内存占用较大 |\n",
    "| 补充       | Series 是 DataFrame 的基础组件 | DataFrame 可以看作是多个 Series 的组合 | Series 和 DataFrame 常常结合使用                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04.数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.处理缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作类型       | 语法                                      | 通俗解释                                                                 | 应用场景                                                                 |\n",
    "|----------------|------------------------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| 检测缺失值     | `df.isna()`                              | 检测 NaN 缺失值，`True` 表示缺失值                                       | 检查数据中是否有缺失值                                                  |\n",
    "| 检测非缺失值   | `df.notna()`                             | 检测非缺失值，`True` 表示该位置有值                                      | 快速检查哪些位置是非缺失数据                                            |\n",
    "| 删除缺失值     | `df.dropna(axis=0, how='any')`          | 删除包含缺失值的行或列（行：`axis=0`；列：`axis=1`），`how='any'`：只要有一个缺失值就删除这一行/列 | 通常适用于数据量较大、缺失值比例较低的情况                              |\n",
    "| 填充缺失值     | `df.fillna(df['label'].mean())`<br>`df.fillna(df['label'].median())`<br>`df.fillna(df['label'].mode())` | 填充缺失值，`value` 可以是一个常量、字典或其他方法（如均值、中位数等）  | 用于数据集存在少量缺失值<br>常见的填充方式：用均值、众数、中位数等       |\n",
    "| 前向填充       | `df.ffill()`                             | 使用前一个有效数据填充缺失值（按行方向填充）                            | 适用于时间序列数据                                                      |\n",
    "| 后向填充       | `df.bfill()`                             | 使用后一个有效数据填充缺失值（按行方向填充）                            | 适用于时间序列数据                                                      |\n",
    "| 插值法填充     | `df.infer_objects(copy=False)`           | `copy=False` 表示不复制，直接原文修改                                    | 当数据有序且缺失值较多时，通过插值法填充缺失数据，保留数据的连续性      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我将把这段代码分成几个逻辑部分，并为每个部分添加详细注释："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.导入库和创建示例DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 创建包含缺失值的示例DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Age': [25, 30, np.nan, 35, 40],          # 包含一个NaN\n",
    "    'Score': [88, np.nan, 85, 79, 90],        # 包含一个NaN\n",
    "    'Date': ['2021-01-01', '2022-02-15', '2023-03-30', '2021-12-01', '2022-05-20']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"原始DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.缺失值检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测缺失值 - 返回布尔值DataFrame，True表示缺失\n",
    "print(\"缺失值检测结果:\")\n",
    "print(df.isna())\n",
    "print('===========检测缺失值示例代码===========')\n",
    "\n",
    "# 检测非缺失值 - 返回布尔值DataFrame，True表示非缺失\n",
    "print(\"\\n非缺失值检测结果:\")\n",
    "print(df.notna())\n",
    "print('===========检测非缺失值示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.删除缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测缺失值 - 返回布尔值DataFrame，True表示缺失\n",
    "print(\"缺失值检测结果:\")\n",
    "print(df.isna())\n",
    "print('===========检测缺失值示例代码===========')\n",
    "\n",
    "# 检测非缺失值 - 返回布尔值DataFrame，True表示非缺失\n",
    "print(\"\\n非缺失值检测结果:\")\n",
    "print(df.notna())\n",
    "print('===========检测非缺失值示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.填充缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充缺失值 - 使用字典指定不同列的不同填充方式\n",
    "df_filled = df.fillna({\n",
    "    'Age': df['Age'].mean(),      # 用Age列的均值填充\n",
    "    'Score': df['Score'].median() # 用Score列的中位数填充\n",
    "})\n",
    "\n",
    "print(\"\\n填充缺失值后的DataFrame:\")\n",
    "print(df_filled)\n",
    "print('===========填充缺失值示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5.前向填充和后向填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向填充 - 用前面的值填充后面的缺失值\n",
    "df_ffill = df.ffill()\n",
    "\n",
    "print(\"\\n前向填充后的DataFrame:\")\n",
    "print(df_ffill)\n",
    "print('===========前向填充示例代码===========')\n",
    "\n",
    "# 后向填充 - 用后面的值填充前面的缺失值\n",
    "df_bfill = df.bfill()\n",
    "\n",
    "print(\"\\n后向填充后的DataFrame:\")\n",
    "print(df_bfill)\n",
    "print('===========后向填充示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.插值法填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 插值法填充 - 这里实际上应该使用interpolate()方法\n",
    "# 原代码中的infer_objects()方法不适用于插值填充，这里修正为正确用法\n",
    "df_interpolated = df.interpolate()  # 线性插值\n",
    "\n",
    "print(\"\\n插值法填充后的DataFrame:\")\n",
    "print(df_interpolated)\n",
    "print('===========插值法填充示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.处理重复值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作类型         | 语法                                      | 通俗解释                                                                 | 应用场景                                                                 |\n",
    "|------------------|------------------------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| 检测重复值       | `df.duplicated()`                        | 检查重复行，返回 `True` 表示重复                                         | 尤其是在数据合并后，可能会产生重复行                                    |\n",
    "| 删除行重复值     | `df.drop_duplicates()`<br>`df.drop_duplicates(keep='last')` | 删除重复行，保留首次出现的行；`keep='last'` 表示保留最后一行             | 确保数据集的唯一性，常用于数据清理                                      |\n",
    "| 删除列重复值     | `df.drop_duplicates(subset=['col1', 'col2'...])` | 删除某些列的重复值，保留其余列相应的值                                   | 在多列数据中，当某些列的值重复时，可以只按这些列去重                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.创建示例DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建包含重复数据的示例DataFrame\n",
    "data = {\n",
    "    'col1': [1, 2, 2, 4, 5],      # 第2行和第3行有重复值2\n",
    "    'col2': ['A', 'B', 'B', 'D', 'E'],  # 第2行和第3行有重复值'B'\n",
    "    'col3': [10, 20, 20, 40, 50]  # 第2行和第3行有重复值20\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"原始DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.检测重复行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测完全重复的行 - 返回布尔Series，True表示该行与前面某行完全重复\n",
    "print(\"检测重复行结果:\")\n",
    "print(df.duplicated())  # 默认检查所有列\n",
    "print('===========检测重复行示例代码===========\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.删除重复行（保留首次出现）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除重复行，默认保留第一次出现的行\n",
    "df_no_duplicates_first = df.drop_duplicates(keep='first')\n",
    "\n",
    "print(\"删除重复行（保留首次出现）:\")\n",
    "print(df_no_duplicates_first)\n",
    "print('===========删除重复行示例代码（首次）===========\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.删除重复行（保留最后出现）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除重复行，保留最后一次出现的行\n",
    "df_no_duplicates_last = df.drop_duplicates(keep='last')\n",
    "\n",
    "print(\"删除重复行（保留最后出现）:\")\n",
    "print(df_no_duplicates_last)\n",
    "print('===========删除重复行示例代码（最后）===========\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5.基于指定列删除重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅根据col1和col2列判断重复，删除重复行\n",
    "df_no_duplicates_cols = df.drop_duplicates(subset=['col1', 'col2'])\n",
    "\n",
    "print(\"基于col1和col2列删除重复行:\")\n",
    "print(df_no_duplicates_cols)\n",
    "print('===========删除列重复值示例代码===========\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.数据标准化与规范化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作类型               | 语法                                                                 | 通俗解释                                                                 | 应用场景                                                                 |\n",
    "|------------------------|---------------------------------------------------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| 转换数据类型           | `df['col'] = df['col'].astype('int')`                              | 转换为指定类型（如 int、float、str 等）                                  | 当数据列的类型不匹配时                                                  |\n",
    "| 标准化数据（Z-score）   | ```python<br>from sklearn.preprocessing import StandardScaler<br>scaler = StandardScaler()<br>df[['col']] = scaler.fit_transform(df[['col']])<br>``` | 标准化：均值为0，标准差为1的标准正态分布                                 | 在机器学习中，当特征值的尺度差异较大时，通过标准化使得数据具有相同的尺度，有助于模型收敛 |\n",
    "| 归一化数据（Min-Max）   | ```python<br>from sklearn.preprocessing import MinMaxScaler<br>scaler = MinMaxScaler()<br>df[['col']] = scaler.fit_transform(df[['col']])<br>``` | 归一化：缩放至最小值和最大值之间（通常是0到1）                           | 适用于神经网络等需要输入数据在一个固定范围内的机器学习算法，确保特征值的尺度一致 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.导入库和创建示例DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 创建示例DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Age': [25, 30, 18, 35, 40],      # 年龄数据\n",
    "    'Score': [88, 17, 85, 79, 90],    # 分数数据\n",
    "    'Date': ['2021-01-01', '2022-02-15', '2023-03-30', '2021-12-01', '2022-05-20']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"原始DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.数据类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将'Age'列转换为整数类型\n",
    "# 虽然原始数据已经是整数，但这里演示类型转换的方法\n",
    "df['Age'] = df['Age'].astype('int')\n",
    "\n",
    "print(\"转换数据类型后的DataFrame:\")\n",
    "print(df)\n",
    "print('===========转换数据类型示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.数据标准化（Z-score标准化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建标准化器对象\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对'Age'列进行标准化（Z-score标准化）\n",
    "# fit_transform方法会计算均值和标准差，并进行转换\n",
    "df[['Age']] = scaler.fit_transform(df[['Age']])\n",
    "\n",
    "print(\"\\n标准化后的DataFrame:\")\n",
    "print(df)\n",
    "print('===========标准化数据示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.数据归一化（Min-Max归一化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建归一化器对象\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 对'Age'列进行归一化（缩放到0-1范围）\n",
    "# fit_transform方法会计算最小值和最大值，并进行转换\n",
    "df[['Age']] = scaler.fit_transform(df[['Age']])\n",
    "\n",
    "print(\"\\n归一化后的DataFrame:\")\n",
    "print(df)\n",
    "print('===========归一化数据示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.数据格式化与处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作类型         | 语法                                      | 通俗解释                                                                 | 应用场景                                                                 |\n",
    "|------------------|------------------------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| 字符串处理       | `df['col'].str.lower()`                 | 字符串列处理，如转换为小写、去掉空格等                                   | 用于文本数据清洗，比如处理不一致的文本格式                              |\n",
    "| 时间戳转换       | `df['date'] = pd.to_datetime(df['date'])` | 转换为 datetime 对象，便于进一步的时间分析                              | 在处理时间序列数据时，将时间列转换为 pandas 时间戳格式，便于后续的时间计算和分析 |\n",
    "| 提取日期特征     | `df['year'] = df['date'].dt.year`       | 从日期列中提取年、月、日、小时、分钟等特征                              | 在进行时间序列分析或预测时，可以从日期中提取有用的特征                   |\n",
    "| 日期差异计算     | `df['date_diff'] = df['end_date'] - df['start_date']` | 计算两个日期之间的差异，返回时间差对象                                  | 计算时间间隔，用于分析周期、持续时间等                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.导入库和创建示例DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 创建包含缺失值的示例DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Age': [25, 30, np.nan, 35, 40],          # 包含一个NaN\n",
    "    'Score': [88, np.nan, 85, 79, 90],        # 包含一个NaN\n",
    "    'Date': ['2021-01-01', '2022-02-15', '2023-03-30', '2021-12-01', '2022-05-20']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"原始DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.字符串处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将Name列转换为小写 - 使用str访问器提供字符串方法\n",
    "df['Name'] = df['Name'].str.lower()\n",
    "\n",
    "print(\"字符串处理后的DataFrame:\")\n",
    "print(df)\n",
    "print('===========字符串处理示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.时间戳转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将Date列从字符串转换为datetime类型\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(\"\\n时间戳转换后的DataFrame:\")\n",
    "print(df)\n",
    "print('===========时间戳转换示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.提取日期特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从日期中提取年份和月份\n",
    "df['Year'] = df['Date'].dt.year     # 提取年份\n",
    "df['Month'] = df['Date'].dt.month   # 提取月份\n",
    "\n",
    "print(\"\\n提取日期特征后的DataFrame:\")\n",
    "print(df)\n",
    "print('===========提取日期特征示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.日期差异计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建开始日期和结束日期列\n",
    "df['Start_Date'] = pd.to_datetime(['2021-01-01', '2022-02-15', '2023-03-30', '2021-12-01', '2022-05-20'])\n",
    "df['End_Date'] = pd.to_datetime(['2022-01-01', '2023-02-15', '2024-03-30', '2022-12-01', '2023-05-20'])\n",
    "\n",
    "# 计算日期差异（返回timedelta对象）\n",
    "df['Date_Diff'] = df['End_Date'] - df['Start_Date']\n",
    "\n",
    "print(\"\\n日期差异计算后的DataFrame:\")\n",
    "print(df)\n",
    "print('===========日期差异计算示例代码===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.数据操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.分组与聚合操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作类型       | 语法                                      | 通俗解释                                                                 | 应用场景                                                                 |\n",
    "|----------------|------------------------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| 按列分组       | `df.groupby('col')`                     | 根据某一列的值将数据分成不同的组                                         | 按照特定类别（如性别、城市等）分组进行统计分析                          |\n",
    "| 按多列分组     | `df.groupby(['col1', 'col2'])`          | 根据多列的值将数据分组                                                 | 根据多个维度（如\"产品\"和\"日期\"）分析数据                                |\n",
    "| 求总和         | `df.groupby('column_name').sum()`       | 对分组后的数据计算每组的总和                                           | 计算每个部门的销售总额                                                  |\n",
    "| 计算均值       | `df.groupby('column_name').mean()`      | 对分组后的数据计算每组的均值                                           | 计算每个学生的平均成绩                                                  |\n",
    "| 计算最大值     | `df.groupby('column_name').max()`       | 对分组后的数据计算每组的最大值                                         | 找出每个部门的最高工资                                                  |\n",
    "| 计算最小值     | `df.groupby('column_name').min()`       | 对分组后的数据计算每组的最小值                                         | 找出每个班级的最低成绩                                                  |\n",
    "| 计数           | `df.groupby('column_name').count()`      | 计算每个分组中非缺失值的数量                                           | 统计每个城市的用户数量                                                  |\n",
    "| 标准差         | `df.groupby('column_name').std()`       | 计算每组的标准差，衡量数据的离散程度                                   | 分析不同部门员工的工资波动                                              |\n",
    "| 自定义函数     | `df.groupby('column_name').agg(lambda x: x.max() - x.min())` | 自定义聚合函数对每个分组的数据进行操作                                 | 求每组的范围（最大值与最小值的差）                                      |\n",
    "| 多重聚合       | `df.groupby('column_name').agg({'col1': 'sum', 'col2': 'mean'})` | 对多组应用不同的聚合函数，对不同列进行不同的聚合操作                   | 计算每个部门的总销售额和平均工龄                                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.创建DataFrame和基础处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 原始数据\n",
    "data = {\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'Department': ['HR', 'HR', 'IT', 'IT', 'Sales', 'Sales'],\n",
    "    'Salary': [50000, 55000, 60000, 65000, 70000, 75000],\n",
    "    'Experience': [5, 6, 3, 4, 10, 12]\n",
    "}\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 将部门列转化为整数（从1开始）\n",
    "df['Department'] = pd.factorize(df['Department'])[0] + 1\n",
    "\n",
    "# 将'Employee'列设置为索引\n",
    "df.set_index('Employee', inplace=True)\n",
    "\n",
    "print(\"原始数据:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.1.基本分组聚合操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按部门分组计算数值型列的均值\n",
    "print(\"\\n按部门分组求均值:\")\n",
    "print(df.groupby('Department').mean())\n",
    "print(\"===========按部门分组求均值示例代码===========\")\n",
    "\n",
    "# 按部门分组计算总和\n",
    "print(\"\\n按部门分组求总和:\")\n",
    "print(df.groupby('Department').sum())\n",
    "print(\"===========按部门分组求总和示例代码===========\")\n",
    "\n",
    "# 按部门分组计算最大值\n",
    "print(\"\\n按部门分组求最大值:\")\n",
    "print(df.groupby('Department').max())\n",
    "print(\"===========按部门分组求最大值示例代码===========\")\n",
    "\n",
    "# 按部门分组计算最小值\n",
    "print(\"\\n按部门分组求最小值:\")\n",
    "print(df.groupby('Department').min())\n",
    "print(\"===========按部门分组求最小值示例代码===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.2.统计函数分组操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按部门分组计算非缺失值数量\n",
    "print(\"\\n按部门分组非缺失值数量:\")\n",
    "print(df.groupby('Department').count())\n",
    "print('===========按部门分组非缺失值数量示例代码===========')\n",
    "\n",
    "# 按部门分组计算标准差\n",
    "print(\"\\n按部门分组求标准差:\")\n",
    "print(df.groupby('Department').std())\n",
    "print(\"===========按部门分组求标准差示例代码===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.3.高级聚合操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按部门分组并使用agg函数计算Salary极差\n",
    "result1 = df.groupby('Department')['Salary'].agg(lambda x: x.max() - x.min())\n",
    "print(\"按部门分组求Salary最大值减去最小值:\")\n",
    "print(result1)\n",
    "print(\"===========\")\n",
    "\n",
    "# 按部门分组并使用agg函数分别计算不同列的聚合\n",
    "result2 = df.groupby('Department').agg({'Salary': 'sum', 'Experience': 'mean'})\n",
    "print(\"按部门分组求Salary总和和Experience均值:\")\n",
    "print(result2)\n",
    "print(\"===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.数据透视与重塑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作类型         | 语法                                                                 | 通俗解释                                                                 | 应用场景                                                                 |\n",
    "|------------------|---------------------------------------------------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| 数据透视表       | `df.pivot(index='date', columns='category', values='sales')`       | 通过数据透视表重新排列数据，index是行索引，columns是列索引，values是值列 | 汇总数据，转换长格式数据为宽格式<br>例如：查看每个月每个产品类别的销售额 |\n",
    "| 数据透视表聚合   | `df.pivot_table(index='date', columns='category', values='sales', aggfunc='sum')` | 在透视表的基础上应用聚合函数（如sum, mean, count等）对值进行汇总        | 对数据进行汇总和聚合<br>例如：计算某个日期和类别下的销售总额、均值等     |\n",
    "| 重塑数据框<br>（长宽转换） | `df.melt(id_vars='id', value_vars=['col1', 'col2'])`               | 将DataFrame从宽格式转换为长格式<br>id_vars是固定列，value_vars是转换列  | 将宽格式数据转换为长格式<br>适用于实验数据、时间序列数据等需要分组分析的场景 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.数据透视表基础操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建示例 DataFrame\n",
    "data = {\n",
    "    'date': ['2024-01-01', '2024-01-01', '2024-02-01', '2024-02-01'],\n",
    "    'category': ['A', 'B', 'A', 'B'],\n",
    "    'sales': [100, 200, 150, 250],\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'col1': [10, 20, 30, 40],\n",
    "    'col2': [40, 50, 60, 70]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.简单数据透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建基本数据透视表\n",
    "pivot_df = df.pivot(index='date', columns='category', values='sales')\n",
    "print(pivot_df)\n",
    "print(\"===========数据透视表示例代码===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.聚合数据透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建带聚合功能的数据透视表\n",
    "pivot_table_df = df.pivot_table(index='date', columns='category', values='sales', aggfunc='sum')\n",
    "print(pivot_table_df)\n",
    "print(\"===========数据透视表聚合示例代码===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5.数据重塑（长宽转换）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将宽格式数据转换为长格式\n",
    "melted_df = df.melt(id_vars='id', value_vars=['col1', 'col2'], var_name='variable', value_name='value')\n",
    "print(melted_df)\n",
    "print(\"===========数据重塑示例代码===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.多维度数据透视"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建多维度数据透视表\n",
    "multi_pivot = df.pivot_table(index=['date'], \n",
    "                            columns=['category'], \n",
    "                            values=['sales', 'col1'],\n",
    "                            aggfunc={'sales':'sum', 'col1':'mean'})\n",
    "print(multi_pivot)\n",
    "print(\"===========多维度数据透视表示例代码===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.7.数据透视表排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据透视表结果进行排序\n",
    "sorted_pivot = pivot_table_df.sort_values(by='date', ascending=False)\n",
    "print(sorted_pivot)\n",
    "print(\"===========数据透视表排序示例代码===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
